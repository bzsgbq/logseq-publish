- 英文自我介绍
	- Hi Professor Qi, I'm very glad to be here for today's interview.
	- My name is Gao Baoqi, and I'm currently a master's student in Computer Science, class of 2025, at Beijing University of Posts and Telecommunications. I'm part of the multimedia group in the State Key Laboratory of Networking and Switching Technology, and my research focuses on 360-degree video streaming.
	- In terms of research, I have published a first-author paper in a CCF-A conference (MM) that primarily addresses long-term viewpoint prediction for 360° videos. Specifically, I proposed a multimodal fusion model that takes historical viewpoint trajectories and saliency maps as inputs. By utilizing self-attention and cross-attention mechanisms, along with a novel saliency representation and gating module I developed, I effectively integrated the information from both modalities through "space-aligned" and "time-varying" fusion to achieve more accurate long-term viewpoint predictions without compromising short-term performance.
	- Additionally, I participated in the ACM MMSys 2024 Grand Challenge organized by ByteDance and achieved first place. In this competition, I proposed a more efficient 360° video on-demand streaming solution aimed at minimizing costs while ensuring high-quality viewport images for users.
	- During my studies, I also engaged in several collaborative research projects with industry partners. One project, in collaboration with Taotian Group, focused on optimizing the first-frame transmission delay for Taobao live broadcasts, successfully reducing the delay by 47% in weak network conditions by optimizing the BBR congestion control algorithm on CDN servers. Another project involved joint innovation with China Mobile Research Institute, where we modeled user experience quality (QoE) for video playback services based on TCP transport layer metrics.
	- Throughout my research journey, I have developed a keen interest in deep learning algorithms, multimodal large models, and AGI. As a result, I have aimed to align my master's research with the multimodal domain, and I am currently applying for a PhD program in related fields, hoping to delve deeper into areas I am passionate about.
	- That concludes my self-introduction. Thank you, Professor!
	-
	- , and I am a master’s student in the Multimedia Group at the State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications (BUPT), graduating in 2025. My research focuses on 360° video streaming transmission.
	- In terms of academic achievements, I have published a first-author paper in the CCF-A conference MM, where I proposed a multimodal fusion model for long-term viewpoint prediction in 360° video. This model combines historical viewpoint trajectories and saliency maps through self-attention and cross-modal attention mechanisms, as well as a novel saliency representation and gating module I designed. This approach effectively integrates spatial alignment and temporal variation, leading to more accurate long-term viewpoint predictions without sacrificing short-term performance.
	- Moreover, I participated in the ACM MMSys 2024 Grand Challenge, organized by ByteDance, where I won first place. In this challenge, I developed a highly efficient 360° video on-demand streaming solution that reduces overhead while maintaining high-quality viewport experience for users.
	- During my time at university, I have also been involved in several collaborative research projects with industry. In collaboration with Taotian Group, I optimized the BBR-based congestion control algorithm on CDN servers, reducing initial frame transmission delay by 47% under poor network conditions. In another project with China Mobile Research Institute, I modeled the QoE of video playback services using TCP layer transmission metrics, improving the accuracy of user experience predictions.
	- Through these research experiences, I have developed a deep interest in deep learning, multimodal models, and AGI. Throughout my master's program, I have strived to align my research focus towards multimodal learning, and I am now applying for a PhD in this direction to pursue further research in areas that truly inspire me.
	- Thank you for your time and consideration.
	- Sincerely,
	  Gao Baoqi