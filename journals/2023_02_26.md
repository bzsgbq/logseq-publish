- [[周报]]
	- 上周已经针对: "使用FedGen以后, VP模型性能不增反减, 甚至不如纯本地训练" 这一问题进行了原因分析, 想出了很多解决方案, 但未来得及全面实施.
	- 而==本周基本把之前想到的解决方案都实际实现了一下==, 主要包括:
		- > 1. 从离线训练场景转换为在线训练场景;
		  2. 给Generator_model设计更复杂的模型结构;
		  3. 不止将y作为作为Generator_model的输入, 而是将y和salmap作为Generator_model的输入;
		  4. 使用salmap作为对视点分布的近似
		  5. 更换用户个性化更强的视点轨迹数据集
	- ==在之前的数据集上, 不管如何调整, 在FedGen框架下训练出的VP模型性能依然欠佳, 最好也只能达到与最原始的联邦学习框架FedAvg基本持平的程度.==
	- ==但是在新尝试的vr-dataset上, 情况有了些许改观.==
		- local:
			- 0.14596259529233402
		- FedAvg:
			- 0.013072452830980767
		- localFedGen:
			- 0.1271546937234647
		- FedGen:
			- 0.009995923290969298
	- 对一系列的测试结果进行分析, ==主要有两点发现:==
		- 在VP预测任务中, 仅使用Generator_model来产生user_model训练时的一部分loss, 似乎并不能很好地将全局知识给到user_model.
		- 目前的情况是, 但凡加入一点个性化的考虑，(比如不下发参数、下发参数和本地参数各占50%、只下发部分layers的参数等）, 最终训练出的VP模型的性能就会变差.
	- 由于目前是在周一凌晨刚刚将以前想到的各种解决方案实现出来, 对一些解决方案还没来得及进行细致的调参; 另外, 感觉目前的各种尝试还是要么全局信息考虑太多, 要么个性化信息考虑太多. ==所以下周会针对 "全局信息与个性化信息的权衡" 方面, 对各种解决方案做一些更细节的调参.==
	- 如果进一步的实践尝试之后, 情况依然没有改观, 则需要回到理论调研上去. 经过这段时间的实际编程, 再回到论文上去, 说不定能有新的理解和启发.